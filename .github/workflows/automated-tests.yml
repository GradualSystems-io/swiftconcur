name: Automated Tests & Coverage

on:
  push:
    branches: [main, develop]
    paths:
      - 'parser/**'
      - 'dashboard/**'
      - 'api/**'
      - 'cli/**'
      - '.github/workflows/automated-tests.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'parser/**'
      - 'dashboard/**'
      - 'api/**'
      - 'cli/**'
      - '.github/workflows/automated-tests.yml'
  workflow_call:

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  MINIMUM_COVERAGE_RUST: 60
  MINIMUM_COVERAGE_JS: 20

concurrency:
  group: tests-${{ github.ref }}
  cancel-in-progress: true

jobs:
  rust-tests:
    name: Rust Tests & Coverage
    runs-on: ubuntu-latest
    outputs:
      coverage: ${{ steps.coverage.outputs.coverage }}
      test-results: ${{ steps.test.outputs.results }}
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install system dependencies (jq, bc, llvm)
        run: |
          sudo apt-get update
          sudo apt-get install -y jq bc llvm || sudo apt-get install -y jq bc llvm-15 || true

      - name: Install Rust toolchain
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          override: true
          components: rustfmt, clippy

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-tests-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-tests-
            ${{ runner.os }}-cargo-

      - name: Install testing tools
        run: |
          # Install cargo-nextest for faster test execution
          cargo install cargo-nextest --locked
          
          # Install tarpaulin for coverage
          cargo install cargo-tarpaulin --locked
          
          # Install cargo-llvm-cov as alternative coverage tool
          cargo install cargo-llvm-cov --locked

      - name: Check code formatting
        run: |
          echo "üîç Checking Rust code formatting..."
          cd parser
          cargo fmt --all -- --check
          
          if [ $? -ne 0 ]; then
            echo "‚ùå Code formatting check failed"
            echo "Run 'cargo fmt' to fix formatting issues"
            exit 1
          fi
          echo "‚úÖ Code formatting check passed"

      - name: Run Clippy lints
        run: |
          echo "üîç Running Clippy lints..."
          cd parser
          cargo clippy --workspace --all-targets --all-features \
            -- -D warnings \
            -D clippy::all \
            -A clippy::pedantic \
            -A clippy::module_name_repetitions \
            -A clippy::missing_errors_doc \
            -A clippy::missing_panics_doc
          
          echo "‚úÖ Clippy lints passed"

      - name: Run unit tests with nextest
        id: test
        run: |
          echo "üß™ Running Rust unit tests..."
          cd parser
          
          # Run tests with JSON output for parsing
          cargo nextest run --workspace --all-features --no-fail-fast \
            --message-format json > ../test-results.json
          
          # Also run with human-readable output
          cargo nextest run --workspace --all-features --no-fail-fast
          
          # Parse test results
          TOTAL_TESTS=$(jq -r '.[] | select(.type == "suite") | .event.passed + .event.failed' ../test-results.json | head -1)
          PASSED_TESTS=$(jq -r '.[] | select(.type == "suite") | .event.passed' ../test-results.json | head -1)
          FAILED_TESTS=$(jq -r '.[] | select(.type == "suite") | .event.failed' ../test-results.json | head -1)
          
          echo "Total tests: $TOTAL_TESTS"
          echo "Passed: $PASSED_TESTS"
          echo "Failed: $FAILED_TESTS"
          
          echo "results={\"total\":$TOTAL_TESTS,\"passed\":$PASSED_TESTS,\"failed\":$FAILED_TESTS}" >> $GITHUB_OUTPUT
          
          if [ "$FAILED_TESTS" -gt 0 ]; then
            echo "‚ùå $FAILED_TESTS test(s) failed"
            exit 1
          fi
          
          echo "‚úÖ All $PASSED_TESTS tests passed"

      - name: Run integration tests
        run: |
          echo "üß™ Running Rust integration tests..."
          cd parser
          cargo test --test integration_tests --no-fail-fast
          echo "‚úÖ Integration tests passed"

      - name: Run doctests
        run: |
          echo "üìö Running Rust doctests..."
          cd parser
          cargo test --doc --no-fail-fast
          echo "‚úÖ Doctests passed"

      - name: Generate test coverage with tarpaulin
        id: coverage
        run: |
          echo "üìä Generating test coverage report..."
          cd parser
          
          # Run tarpaulin to generate coverage
          cargo tarpaulin \
            --workspace \
            --engine llvm \
            --exclude-files '../target/*' \
            --exclude-files 'tests/*' \
            --exclude-files '*/tests/*' \
            --out xml \
            --out html \
            --out json \
            --output-dir ../coverage \
            --timeout 120 \
            --fail-under $MINIMUM_COVERAGE_RUST
          
          # Extract coverage percentage
          COVERAGE=$(jq -r '.files | map(.summary.lines.percent) | add / length' ../coverage/tarpaulin-report.json)
          echo "Coverage: ${COVERAGE}%"
          
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          
          # Check if coverage meets minimum threshold
          if (( $(echo "$COVERAGE < $MINIMUM_COVERAGE_RUST" | bc -l) )); then
            echo "‚ùå Coverage $COVERAGE% is below minimum threshold $MINIMUM_COVERAGE_RUST%"
            exit 1
          fi
          
          echo "‚úÖ Coverage $COVERAGE% meets minimum threshold $MINIMUM_COVERAGE_RUST%"

      - name: Generate detailed coverage report
        run: |
          echo "üìã Generating detailed coverage report..."
          cd coverage
          
          # Create detailed coverage summary
          cat > coverage-summary.md << EOF
          # üìä Rust Code Coverage Report
          
          **Overall Coverage**: ${COVERAGE}%
          **Minimum Required**: $MINIMUM_COVERAGE_RUST%
          **Status**: $([ "$COVERAGE" -ge "$MINIMUM_COVERAGE_RUST" ] && echo "‚úÖ PASSED" || echo "‚ùå FAILED")
          
          ## Coverage by File
          
          EOF
          
          # Add per-file coverage (if tarpaulin JSON is available)
          if [ -f tarpaulin-report.json ]; then
            jq -r '.files[] | "| \(.name) | \(.summary.lines.percent)% |"' tarpaulin-report.json | \
            sed '1i| File | Coverage |' | \
            sed '2i|------|----------|' >> coverage-summary.md
          fi
          
          echo "" >> coverage-summary.md
          echo "## Test Results" >> coverage-summary.md
          echo "" >> coverage-summary.md
          echo "- **Total Tests**: $(echo '${{ steps.test.outputs.results }}' | jq -r '.total')" >> coverage-summary.md
          echo "- **Passed**: $(echo '${{ steps.test.outputs.results }}' | jq -r '.passed')" >> coverage-summary.md
          echo "- **Failed**: $(echo '${{ steps.test.outputs.results }}' | jq -r '.failed')" >> coverage-summary.md
          echo "" >> coverage-summary.md
          echo "*Generated on $(date -u)*" >> coverage-summary.md

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: rust-coverage-reports
          path: |
            coverage/
            test-results.json
          retention-days: 30

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: always()
        with:
          file: coverage/cobertura.xml
          flags: rust
          name: rust-coverage
          fail_ci_if_error: false

  javascript-tests:
    name: JavaScript/TypeScript Tests & Coverage
    runs-on: ubuntu-latest
    strategy:
      matrix:
        component: [dashboard, api]
    outputs:
      coverage-dashboard: ${{ steps.coverage-dashboard.outputs.coverage }}
      coverage-api: ${{ steps.coverage-api.outputs.coverage }}
    
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: ${{ matrix.component }}/package-lock.json

      - name: Install jq and bc
        run: |
          sudo apt-get update
          sudo apt-get install -y jq bc

      - name: Install dependencies
        run: |
          cd ${{ matrix.component }}
          npm ci || npm install

      - name: Check TypeScript compilation
        run: |
          echo "üîç Checking TypeScript compilation..."
          cd ${{ matrix.component }}
          if [ -f tsconfig.json ]; then
            echo "‚ÑπÔ∏è Running type-check (non-blocking) in ${{ matrix.component }}"
            npm run type-check || true
          else
            echo "‚ÑπÔ∏è No TypeScript configuration found, skipping"
          fi

      - name: Run ESLint
        run: |
          echo "üîç Running ESLint..."
          cd ${{ matrix.component }}
          if [ -f .eslintrc.js ] || [ -f .eslintrc.json ] || [ -f eslint.config.js ]; then
            npm run lint || npx eslint . --ext .js,.ts,.tsx
            echo "‚úÖ ESLint check passed"
          else
            echo "‚ÑπÔ∏è No ESLint configuration found, skipping"
          fi

      - name: Run tests with coverage
        id: coverage
        run: |
          echo "üß™ Running ${{ matrix.component }} tests with coverage..."
          cd ${{ matrix.component }}
          
          # Check which test runner is configured
          if npm run test:coverage --dry-run 2>/dev/null; then
            npm run test:coverage
          elif npm run test -- --coverage 2>/dev/null; then
            npm run test -- --coverage --watchAll=false
          elif command -v vitest &> /dev/null; then
            npx vitest run --coverage
          else
            # Fallback to basic test command
            npm test
            echo "‚ö†Ô∏è No coverage configuration found for ${{ matrix.component }}"
          fi
          
          # Extract coverage percentage if coverage report exists
          COVERAGE="0"
          if [ -f coverage/coverage-summary.json ]; then
            COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json)
          elif [ -f coverage/lcov-report/index.html ]; then
            # Parse coverage from HTML report if JSON not available
            COVERAGE=$(grep -o '[0-9]\+\.[0-9]\+%' coverage/lcov-report/index.html | head -1 | sed 's/%//')
          fi
          
          echo "Coverage for ${{ matrix.component }}: ${COVERAGE}%"
          echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
          
          # Check coverage threshold
          if (( $(echo "$COVERAGE < $MINIMUM_COVERAGE_JS" | bc -l) )); then
            echo "‚ùå Coverage $COVERAGE% is below minimum threshold $MINIMUM_COVERAGE_JS%"
            exit 1
          fi
          
          echo "‚úÖ Coverage $COVERAGE% meets minimum threshold $MINIMUM_COVERAGE_JS%"

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ matrix.component }}-coverage-reports
          path: ${{ matrix.component }}/coverage/
          retention-days: 30

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: always()
        with:
          directory: ${{ matrix.component }}/coverage
          flags: ${{ matrix.component }}
          name: ${{ matrix.component }}-coverage
          fail_ci_if_error: false

  integration-tests:
    name: Integration & E2E Tests
    runs-on: ubuntu-latest
    needs: [rust-tests]
    if: always() && needs.rust-tests.result == 'success'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: swiftconcur_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - uses: actions/checkout@v4

      - name: Setup test environment
        run: |
          echo "üîß Setting up integration test environment..."
          
          # Install required tools
          sudo apt-get update
          sudo apt-get install -y postgresql-client jq
          
          # Verify database connection
          PGPASSWORD=postgres psql -h localhost -U postgres -d swiftconcur_test -c "SELECT 1;"
          
          echo "‚úÖ Test environment ready"

      - name: Build parser for integration tests
        run: |
          echo "üî® Building parser for integration tests..."
          cd parser
          cargo build --release
          
          # Make binary available for integration tests
          cp target/release/swiftconcur-parser ../swiftconcur-cli
          chmod +x ../swiftconcur-cli

      - name: Run parser integration tests
        run: |
          echo "üß™ Running parser integration tests..."
          
          # Test with sample xcodebuild output
          cd parser/tests/fixtures
          
          # Test JSON parsing
          echo "Testing JSON parsing..."
          ../../../swiftconcur-cli -f xcresult_single_warning.json --format json > /tmp/test_output.json
          
          # Verify output contains expected warnings
          if jq -e '.warnings | length > 0' /tmp/test_output.json; then
            echo "‚úÖ JSON parsing test passed"
          else
            echo "‚ùå JSON parsing test failed"
            exit 1
          fi
          
          # Test markdown output
          echo "Testing markdown output..."
          ../../../swiftconcur-cli -f xcresult_single_warning.json --format markdown > /tmp/test_output.md
          
          if grep -q "Swift Concurrency Warnings" /tmp/test_output.md; then
            echo "‚úÖ Markdown output test passed"
          else
            echo "‚ùå Markdown output test failed"
            exit 1
          fi

      - name: Run dashboard integration tests
        run: |
          if [ -d dashboard ] && [ -f dashboard/package.json ]; then
            echo "üß™ Running dashboard integration tests..."
            cd dashboard
            
            if npm run test:integration --dry-run 2>/dev/null; then
              npm run test:integration
            else
              echo "‚ÑπÔ∏è No integration tests configured for dashboard"
            fi
          fi

      - name: Run API integration tests
        run: |
          if [ -d api ] && [ -f api/package.json ]; then
            echo "üß™ Running API integration tests..."
            cd api
            
            if npm run test:integration --dry-run 2>/dev/null; then
              npm run test:integration
            else
              echo "‚ÑπÔ∏è No integration tests configured for API"
            fi
          fi

  coverage-report:
    name: Coverage Report & Quality Gates
    runs-on: ubuntu-latest
    needs: [rust-tests, javascript-tests]
    if: always()
    
    steps:
      - uses: actions/checkout@v4

      - name: Download all coverage reports
        uses: actions/download-artifact@v4
        with:
          path: coverage-reports

      - name: Install jq for JSON processing
        run: sudo apt-get install -y jq bc

      - name: Generate comprehensive coverage report
        run: |
          echo "üìä Generating comprehensive coverage report..."
          
          # Extract coverage data
          RUST_COVERAGE="${{ needs.rust-tests.outputs.coverage }}"
          DASHBOARD_COVERAGE="${{ needs.javascript-tests.outputs.coverage-dashboard }}"
          API_COVERAGE="${{ needs.javascript-tests.outputs.coverage-api }}"
          
          # Calculate overall coverage (weighted by codebase size estimate)
          # Rust: 60%, Dashboard: 25%, API: 15%
          OVERALL_COVERAGE=$(echo "scale=2; ($RUST_COVERAGE * 0.6 + $DASHBOARD_COVERAGE * 0.25 + $API_COVERAGE * 0.15)" | bc)
          
          # Create comprehensive report
          cat > coverage-report.md << EOF
          # üìä SwiftConcur Test Coverage Report
          
          **Generated**: $(date -u)  
          **Branch**: ${{ github.ref_name }}  
          **Commit**: ${{ github.sha }}  
          
          ## Overall Coverage: ${OVERALL_COVERAGE}%
          
          | Component | Coverage | Status | Minimum Required |
          |-----------|----------|---------|------------------|
          | Rust Parser | ${RUST_COVERAGE}% | $([ "${RUST_COVERAGE%.*}" -ge "$MINIMUM_COVERAGE_RUST" ] && echo "‚úÖ PASS" || echo "‚ùå FAIL") | $MINIMUM_COVERAGE_RUST% |
          | Dashboard | ${DASHBOARD_COVERAGE}% | $([ "${DASHBOARD_COVERAGE%.*}" -ge "$MINIMUM_COVERAGE_JS" ] && echo "‚úÖ PASS" || echo "‚ùå FAIL") | $MINIMUM_COVERAGE_JS% |
          | API | ${API_COVERAGE}% | $([ "${API_COVERAGE%.*}" -ge "$MINIMUM_COVERAGE_JS" ] && echo "‚úÖ PASS" || echo "‚ùå FAIL") | $MINIMUM_COVERAGE_JS% |
          
          ## Test Results Summary
          
          $(echo '${{ needs.rust-tests.outputs.test-results }}' | jq -r '"- **Rust Tests**: \(.passed) passed, \(.failed) failed, \(.total) total"')
          
          ## Quality Gates
          
          EOF
          
          # Quality gate checks
          QUALITY_GATE_PASSED=true
          
          if [ "${RUST_COVERAGE%.*}" -lt "$MINIMUM_COVERAGE_RUST" ]; then
            echo "- ‚ùå Rust coverage below threshold ($RUST_COVERAGE% < $MINIMUM_COVERAGE_RUST%)" >> coverage-report.md
            QUALITY_GATE_PASSED=false
          else
            echo "- ‚úÖ Rust coverage meets threshold ($RUST_COVERAGE% >= $MINIMUM_COVERAGE_RUST%)" >> coverage-report.md
          fi
          
          if [ "${DASHBOARD_COVERAGE%.*}" -lt "$MINIMUM_COVERAGE_JS" ]; then
            echo "- ‚ùå Dashboard coverage below threshold ($DASHBOARD_COVERAGE% < $MINIMUM_COVERAGE_JS%)" >> coverage-report.md
            QUALITY_GATE_PASSED=false
          else
            echo "- ‚úÖ Dashboard coverage meets threshold ($DASHBOARD_COVERAGE% >= $MINIMUM_COVERAGE_JS%)" >> coverage-report.md
          fi
          
          if [ "${API_COVERAGE%.*}" -lt "$MINIMUM_COVERAGE_JS" ]; then
            echo "- ‚ùå API coverage below threshold ($API_COVERAGE% < $MINIMUM_COVERAGE_JS%)" >> coverage-report.md
            QUALITY_GATE_PASSED=false
          else
            echo "- ‚úÖ API coverage meets threshold ($API_COVERAGE% >= $MINIMUM_COVERAGE_JS%)" >> coverage-report.md
          fi
          
          echo "" >> coverage-report.md
          
          if [ "$QUALITY_GATE_PASSED" = true ]; then
            echo "## ‚úÖ Overall Status: PASSED" >> coverage-report.md
            echo "All quality gates passed. Code is ready for merge." >> coverage-report.md
          else
            echo "## ‚ùå Overall Status: FAILED" >> coverage-report.md
            echo "One or more quality gates failed. Please improve test coverage before merging." >> coverage-report.md
          fi
          
          echo "" >> coverage-report.md
          echo "---" >> coverage-report.md
          echo "*This report was automatically generated by the SwiftConcur CI pipeline*" >> coverage-report.md
          
          # Output for other steps
          echo "QUALITY_GATE_PASSED=$QUALITY_GATE_PASSED" >> $GITHUB_ENV
          echo "OVERALL_COVERAGE=$OVERALL_COVERAGE" >> $GITHUB_ENV

      - name: Create coverage badges
        run: |
          echo "üè∑Ô∏è Creating coverage badges..."
          mkdir -p badges
          
          # Create badge URLs (these would typically use shields.io or similar service)
          RUST_COLOR=$([ "${RUST_COVERAGE%.*}" -ge "$MINIMUM_COVERAGE_RUST" ] && echo "green" || echo "red")
          DASHBOARD_COLOR=$([ "${DASHBOARD_COVERAGE%.*}" -ge "$MINIMUM_COVERAGE_JS" ] && echo "green" || echo "red")
          API_COLOR=$([ "${API_COVERAGE%.*}" -ge "$MINIMUM_COVERAGE_JS" ] && echo "green" || echo "red")
          
          echo "Rust Coverage: ![Coverage](https://img.shields.io/badge/coverage-${RUST_COVERAGE}%25-${RUST_COLOR})" > badges/rust-coverage.md
          echo "Dashboard Coverage: ![Coverage](https://img.shields.io/badge/coverage-${DASHBOARD_COVERAGE}%25-${DASHBOARD_COLOR})" > badges/dashboard-coverage.md
          echo "API Coverage: ![Coverage](https://img.shields.io/badge/coverage-${API_COVERAGE}%25-${API_COLOR})" > badges/api-coverage.md

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-coverage-report
          path: |
            coverage-report.md
            badges/
          retention-days: 30

      - name: Comment coverage report on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('coverage-report.md', 'utf8');
            
            // Find existing comment
            const comments = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            });
            
            const existingComment = comments.data.find(comment => 
              comment.body.includes('SwiftConcur Test Coverage Report')
            );
            
            if (existingComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                comment_id: existingComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            }

      - name: Set commit status
        if: always()
        run: |
          if [ "$QUALITY_GATE_PASSED" = true ]; then
            echo "‚úÖ All quality gates passed - Coverage: $OVERALL_COVERAGE%"
          else
            echo "‚ùå Quality gates failed - Coverage: $OVERALL_COVERAGE%"
            exit 1
          fi

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [rust-tests, javascript-tests, integration-tests, coverage-report]
    if: always()
    
    steps:
      - name: Test Summary
        run: |
          echo "üìã Test Execution Summary"
          echo "=========================="
          echo "Rust Tests: ${{ needs.rust-tests.result }}"
          echo "JavaScript Tests: ${{ needs.javascript-tests.result }}"
          echo "Integration Tests: ${{ needs.integration-tests.result }}"
          echo "Coverage Report: ${{ needs.coverage-report.result }}"
          echo ""
          
          # Determine overall status
          if [[ "${{ needs.rust-tests.result }}" == "success" && 
                "${{ needs.javascript-tests.result }}" == "success" && 
                "${{ needs.integration-tests.result }}" == "success" && 
                "${{ needs.coverage-report.result }}" == "success" ]]; then
            echo "‚úÖ All tests passed successfully!"
            echo "Code is ready for merge."
          else
            echo "‚ùå Some tests failed or were skipped."
            echo "Please review the failing tests before merging."
            exit 1
          fi
