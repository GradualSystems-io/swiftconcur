import OpenAI from 'openai';
import type { Env } from '../types';
import type { Warning } from '../models/warning';

/**
 * OpenAI integration for AI summary generation
 */
export class OpenAIService {
  private client: OpenAI;
  
  constructor(env: Env) {
    this.client = new OpenAI({
      apiKey: env.OPENAI_API_KEY,
    });
  }
  
  /**
   * Generate AI summary for warning run
   */
  async generateSummary(data: {
    repo_id: string;
    run_id: string;
    warnings: Warning[];
    metadata: {
      commit_sha: string;
      branch: string;
      scheme: string;
      swift_version: string;
    };
  }): Promise<string> {
    try {
      const analysis = this.analyzeWarnings(data.warnings);
      const prompt = this.buildPrompt(data, analysis);
      
      const completion = await this.client.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: this.getSystemPrompt(),
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: 0.3,
        max_tokens: 500,
        top_p: 0.9,
        frequency_penalty: 0.1,
        presence_penalty: 0.1,
      });
      
      const summary = completion.choices[0]?.message?.content;
      if (!summary) {
        throw new Error('No summary generated by OpenAI');
      }
      
      return this.postProcessSummary(summary);
      
    } catch (error) {
      console.error('Error generating AI summary:', error);
      
      // Fallback to basic summary
      return this.generateFallbackSummary(data.warnings);
    }
  }
  
  /**
   * Analyze warnings to extract patterns and insights
   */
  private analyzeWarnings(warnings: Warning[]) {
    const analysis = {
      totalCount: warnings.length,
      severityCounts: {
        critical: 0,
        high: 0,
        medium: 0,
        low: 0,
      },
      typeCounts: {
        actor_isolation: 0,
        sendable: 0,
        data_race: 0,
        performance: 0,
      },
      fileGroups: new Map<string, number>(),
      mostCritical: warnings
        .filter(w => w.severity === 'critical' || w.severity === 'high')
        .slice(0, 3),
    };
    
    // Count by severity and type
    warnings.forEach(warning => {
      analysis.severityCounts[warning.severity]++;
      analysis.typeCounts[warning.type]++;
      
      // Group by file
      const count = analysis.fileGroups.get(warning.file_path) || 0;
      analysis.fileGroups.set(warning.file_path, count + 1);
    });
    
    return analysis;
  }
  
  /**
   * Build prompt for OpenAI
   */
  private buildPrompt(data: any, analysis: any): string {
    const topFiles = Array.from(analysis.fileGroups.entries())
      .sort(([, a], [, b]) => b - a)
      .slice(0, 3)
      .map(([file, count]) => `${file}: ${count} warnings`);
    
    return `
Analyze these Swift concurrency warnings from a CI build:

**Build Context:**
- Repository: ${data.repo_id}
- Branch: ${data.metadata.branch}
- Commit: ${data.metadata.commit_sha.substring(0, 7)}
- Scheme: ${data.metadata.scheme}
- Swift Version: ${data.metadata.swift_version}

**Warning Summary:**
- Total: ${analysis.totalCount} warnings
- Critical: ${analysis.severityCounts.critical}
- High: ${analysis.severityCounts.high}
- Medium: ${analysis.severityCounts.medium}
- Low: ${analysis.severityCounts.low}

**By Type:**
- Actor Isolation: ${analysis.typeCounts.actor_isolation}
- Sendable: ${analysis.typeCounts.sendable}
- Data Race: ${analysis.typeCounts.data_race}
- Performance: ${analysis.typeCounts.performance}

**Most Affected Files:**
${topFiles.join('\n')}

**Top Critical Issues:**
${analysis.mostCritical.map((w: Warning, i: number) => 
  `${i + 1}. ${w.file_path}:${w.line_number} - ${w.message.substring(0, 100)}...`
).join('\n')}

Provide a concise analysis focusing on:
1. Executive summary (1 sentence)
2. Key patterns and root causes
3. Top 3 actionable recommendations
4. Risk assessment (Low/Medium/High)

Keep response under 200 words and developer-focused.
`;
  }
  
  /**
   * Get system prompt for AI assistant
   */
  private getSystemPrompt(): string {
    return `You are a Swift concurrency expert helping developers fix threading and actor isolation issues. 

Key principles:
- Be concise and actionable
- Focus on root causes, not just symptoms
- Prioritize critical data race issues
- Suggest specific Swift concurrency patterns
- Use developer-friendly language
- Provide concrete next steps

Response format:
üéØ **Summary:** [One sentence overview]

üîç **Key Patterns:**
- [Pattern 1]
- [Pattern 2]

üí° **Recommendations:**
1. [Specific action 1]
2. [Specific action 2] 
3. [Specific action 3]

‚ö†Ô∏è **Risk Level:** [Low/Medium/High] - [Brief justification]`;
  }
  
  /**
   * Post-process AI summary for consistency
   */
  private postProcessSummary(summary: string): string {
    // Clean up common AI response issues
    let cleaned = summary.trim();
    
    // Remove redundant prefixes
    cleaned = cleaned.replace(/^(Here's|Here is|Based on|The analysis shows)/i, '');
    
    // Ensure proper emoji formatting
    cleaned = cleaned.replace(/:\w+:/g, ''); // Remove text emojis
    
    // Limit length
    if (cleaned.length > 800) {
      cleaned = cleaned.substring(0, 800) + '...';
    }
    
    return cleaned;
  }
  
  /**
   * Generate fallback summary when AI fails
   */
  private generateFallbackSummary(warnings: Warning[]): string {
    const analysis = this.analyzeWarnings(warnings);
    
    const riskLevel = analysis.severityCounts.critical > 0 ? 'High' :
                     analysis.severityCounts.high > 5 ? 'Medium' : 'Low';
    
    const topType = Object.entries(analysis.typeCounts)
      .sort(([, a], [, b]) => b - a)[0][0];
    
    return `üéØ **Summary:** Found ${analysis.totalCount} Swift concurrency warnings, primarily ${topType.replace('_', ' ')} issues.

üîç **Key Patterns:**
- ${analysis.severityCounts.critical} critical issues requiring immediate attention
- ${analysis.severityCounts.high} high-priority warnings affecting thread safety

üí° **Recommendations:**
1. Address critical data race conditions first
2. Review actor isolation boundaries
3. Ensure Sendable conformance for shared types

‚ö†Ô∏è **Risk Level:** ${riskLevel} - ${riskLevel === 'High' ? 'Critical issues detected' : 'Manageable warning count'}`;
  }
  
  /**
   * Generate suggested fixes for specific warning
   */
  async generateWarningFix(warning: Warning): Promise<string> {
    try {
      const prompt = `
Fix this Swift concurrency warning:

File: ${warning.file_path}:${warning.line_number}
Type: ${warning.type}
Severity: ${warning.severity}
Message: ${warning.message}

Code context:
${warning.code_context.before.join('\n')}
> ${warning.code_context.line}
${warning.code_context.after.join('\n')}

Provide a specific fix suggestion in 2-3 sentences.
`;
      
      const completion = await this.client.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: 'You are a Swift expert. Provide concise, actionable fixes for concurrency warnings.',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: 0.2,
        max_tokens: 150,
      });
      
      return completion.choices[0]?.message?.content || 'Unable to generate fix suggestion.';
      
    } catch (error) {
      console.error('Error generating warning fix:', error);
      return 'Review concurrency patterns and consider using proper isolation mechanisms.';
    }
  }
  
  /**
   * Health check for OpenAI service
   */
  async healthCheck(): Promise<boolean> {
    try {
      const response = await this.client.chat.completions.create({
        model: 'gpt-4o',
        messages: [{ role: 'user', content: 'Test' }],
        max_tokens: 5,
      });
      
      return !!response.choices[0]?.message?.content;
      
    } catch (error) {
      console.error('OpenAI health check failed:', error);
      return false;
    }
  }
}

/**
 * Process AI summary queue message
 */
export async function processAISummary(
  message: {
    repo_id: string;
    run_id: string;
    warnings: Warning[];
    metadata: any;
  },
  env: Env
): Promise<void> {
  try {
    const openai = new OpenAIService(env);
    const summary = await openai.generateSummary(message);
    
    // Update database with AI summary
    const { createSupabaseService } = await import('./supabase');
    const supabase = createSupabaseService(env);
    await supabase.updateAISummary(message.run_id, summary);
    
    console.log(`AI summary generated for run ${message.run_id}`);
    
  } catch (error) {
    console.error('Failed to process AI summary:', error);
    throw error; // This will cause the message to be retried
  }
}